# 咱們一起做資料清理和前處理
## 今日學習目標
- 資料如何清理
    - 什麼是資料清理？
- 資料前處理的方式
    - 為什麼資料要前處理呢？前處裡有何好處？
- 學習 sklearn 中四種不同資料前處理方式
    - StandardScaler (平均值和標準差)
    - MinMaxScaler(最小最大值標準化)
    - MaxAbsScaler（絕對值最大標準化）
    - RobustScaler

## 前言
很多演算法對數據範圍非常的敏感。因此為了要讓模型訓練的更強大，通常的做法是對特徵進行調節，使得數據更適合這些演算法。一般來說，我們在做機器學習時往往會做特徵的正規化。


## 載入相關套件

```py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris

np.set_printoptions(suppress=True)
```

## 1) 載入資料集
今天的範例我們延續昨天的例子，鳶尾花朵資料集進行資料正規化的示範。

```py
iris = load_iris()
df_train = pd.DataFrame(data= np.c_[iris['data'], iris['target']],
                     columns= ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species'])
df_train
```

## 2) 檢查缺失值
使用 numpy 所提供的函式來檢查是否有 NA 缺失值，假設有缺失值使用 `dropna()` 來移除。使用的時機在於當只有少量的缺失值適用，若遇到有大量缺失值的情況，或是本身的資料量就很少的情況下建議可以透過機器學習的方法補值來預測缺失值。

```py
X = df_train.drop(labels=['Species'],axis=1).values # 移除Species並取得剩下欄位資料
y = df_train['Species']
# checked missing data
print("checked missing data(NAN mount):",len(np.where(np.isnan(X))[0]))
```

輸出結果：
```
checked missing data(NAN mount): 0
```

由於 Sklearn 所提供的資料集非常乾淨，若你收集到的資料有許多的缺失值或是本身資料量就不多的強況下，建議好好的去處理這些缺漏的值。通常補值的方法可分為手動填值與插值法。首先手動填值可以以該欄位所有資料的算術平均數或中位數做填補的依據。再者使用以出現頻率最高的值做填補也是常見的補值方式。另一種差值法是透過時間或空間上的技巧處理這些缺值，例如當資料是有時間序列的因素存在時，可以利用該筆缺失欄位附近的時間點的資料加總並平均。

## 3) 切割訓練集與測試集
我們透過 Sklearn 所提供的 `train_test_split()` 方法來為我們的資料進行訓練集與測試集的切割。在此方法中我們可以設定一些參數來讓我們切割的資料更多樣性。其中 `test_size` 參數就是設定測試集的比例，範例中我們設定 0.3 即代表訓練集與測試集的比例為 7:3。另外預設切割資料的方式是隨機切割 `shuffle=True`，若要確保

```py
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

print('train shape:', X_train.shape)
print('test shape:', X_test.shape)
```

輸出結果：
```
train shape: (105, 4)
test shape: (45, 4)
```


### Standardization平均&變異數標準化
將所有特徵標準化，也就是高斯分佈。使得數據的平均值為0，方差為1。適合的使用時機於當有些特徵的方差過大時，使用標準化能夠有效地讓模型快速收斂。