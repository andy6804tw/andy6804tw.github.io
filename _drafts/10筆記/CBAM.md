## 前言
CBAM 為提出 BAM 架構的原班人馬，同樣都是在說明通道與空間注意力的混合方法。CBAM 主要是改善原先在 SKNet 上僅使用 GAP 來萃取通道資訊資訊量遺失太多問題，以及透過結合通道域和空間域的概念將兩個模塊串連起來形成 CBAM 模型。雖然 BAM 與 CBAM 都被稱為混合域(Channel & Spatial Attention)的代表方法，但是我們也可以說 CBAM 做了不同實驗改善了 BAM 架構。

![](https://i.imgur.com/se8pdv3.png)

- 論文： [CBAM: Convolutional Block Attention Module](https://arxiv.org/abs/1807.06521) (ECCV 2018)
- 程式碼： [GitHub](https://github.com/Jongchan/attention-module)


## 為什麼要混合？
平時在做卷積時每一層網路的輸出都是透過許多個 filter 進行特徵篩選。隨著網路越深層感受野也逐漸變大。但是在中間的網路層中每一層的特徵圖(feature maps)都是有用的資訊嗎？因此我們可以透過注意力機制來對這些特徵進行更進一步的篩選，在先前的文章中有提到電腦視覺中注意力有非常多的方法。然而其中我們可以透過同時觀察通道維度與空間維度的資訊進行注意力機制評估。不同的維度所代表的意義是不同的，它們本身所攜帶的訊息也是不同的。相對的空間維度的資訊也是如此。對於通道而言多數是特徵抽象的表達(What)，對於空間而言所擁有的位置信息更為豐富(where)。

![](https://i.imgur.com/I5Q4ppl.png)

## 通道空間注意力機制
CBAM: Convolutional Block Attention Module 從論文名字我們可以發現作者提出的是一個卷積模塊，這意味著他可以被引用在任何網路架構中。然而這個模塊可以接收任一層卷積神經網路的輸出，並依序經過通道注意力模塊以及空間注意力模塊。

![](https://i.imgur.com/K0kFDZk.png)

### 通道注意力模塊
首先給定一個輸入特徵圖 F 同時經過全局平均池化(GAP)和全局最大池化(GMP)操作，分別得到兩個不同的空間的表徵向量。接著這兩個向量共享一個 MLP 全連階層網路。此 MLP 為兩個全連接層組成首先降維至原來輸入的 r 分之一，接著再升維到原始長度(c)輸出特徵數通道的權重值。得到兩個經過 MLP 網路的向量後進行相加再經過一個 Sigmoid 得到最後的通道域注意力向量。

![](https://i.imgur.com/wugNA1n.png)

### 空間注意力模塊
首先給定一個輸入特徵圖 F 沿著通道維度同時經過全局平均池化(GAP)和全局最大池化(GMP)兩種操作，每張圖的大小為 W*H*1 分別得到兩個不同的空間的特徵圖。接著將這兩張特徵圖進行拼接變成 H*W*2，然後經過一個卷積核為 7*7 的捲積操作(增大感受野)，再經過一個 sigmoid 激發函數，最後得到空間注意力特徵圖。

![](https://i.imgur.com/ryVvc31.png)

## 注意力機制混合比較 (BAM vs CBAM)
在 BAM 方法中是採用平行的分支分別對輸入進行通道域和空間域的注意力機制。再將這兩個輸出進行融合得到混合的注意力特徵圖，最後再對原特徵圖 F 進行校正。
然而 CBAM 方法是採用串連方式，首先通道注意力特徵圖對原特徵圖 F 進行校正得到 F’ 接著空間注意力特徵圖對特徵圖 F’ 再進行校正得到 F’’。

![](https://i.imgur.com/FFHvp2a.png)

> 人的大腦視覺皮層先掌握全局訊息，接著再集中某個區域的訊息。如果按照這個角度去理解就是先通道注意力(What)再空間注意力(Where)。

## 論文實驗
關於 CBAM 結構作者在論文中分別進行多項實現，並比較在哪種網路架構下能得到更好的結果。
### 通道注意力中的探討
透過 RestNet50 與三種不同組合：全局平均池化、全局最大池化、全局平均池化＋全局最大池化。並應用在通道注意力模塊中可以發現全局平均池化＋全局最大池化兩者同時採用效果更好。

![](https://i.imgur.com/hkOX5qX.png)

### 空間注意力中的探討
在空間注意力中實驗透過 avg&max 進行特徵圖降維再進入一個 7*7 的卷積效果最佳。

![](https://i.imgur.com/s4GTnfN.png)

### 通道和空間注意力組合方式的探討
在實驗中進行了不同組合的注意力混合方式，最終得到先通道域後空間域的機制效果最好。同時也符合我們人類對事物觀察的習性。

![](https://i.imgur.com/I5VyyCx.png)

## 實驗結果
左邊兩圖為 CBAM 嵌入到不同的 backbone 並在物件偵測任務上的結果。分別有 COC 與 VOC 數據集。右邊是在 ImageNet-1K 圖像分類任務。
我們可以發現加入了 CBAM 模塊在所有的任務上都有些許的提升。

![](https://i.imgur.com/AMovYki.png)

我們可以透過 GradCAM 來比較各模型的解釋能力。其中 CBAM 更能抓住目標物的整個物體。

![](https://i.imgur.com/ho6mkN1.png)



