# Yoshua Bengio：注意力是「有意識」AI的核心要素

本篇文章內容參考於 ICLR 2020 Yoshua Bengio (約書亞·班吉歐) 的演講內容並進行翻譯與整理，相關的影片與簡報在[官方](https://iclr.cc/virtual_2020/speaker_7.html)都有提供資源。在此次演講當中 Bengio 以有意識先驗 (The consciousness prior) 為主旨，特別是深度學習與意識的關係。其概念核心就是注意力機制，他將機器學習注意力機制與我們人類的大腦注意力方式進行了比較。借鑑於人類的注意力機制專注於重點，促使注意力機制是作為一種通用的學習方式。


## 將機器學習用於意識 & 將意識用於機器學習
近幾年來正有一群科學家想讓機器學習更具有獨立思考的特性，也就是具有意識的思考、假設與推論。並擺脫傳統的深度學習無意識的特性，透過某種形式模擬人類的經驗萃取達到更進階的深度學習。

1. 形式化定義並測試特定的意識的假設函數
2. 揭開意識的神秘面紗
3. 從計算和統計的角度（例如，系統的泛化）理解意識演化的優勢
4. 將這些優勢應用於學習代理

![](https://i.imgur.com/37i9DuJ.png)

## 有意識的人工智慧
`深度學習2.0`是由加拿大計算機科學家 Yoshua Bengio 所提出的。其想法引用了丹尼爾·卡尼曼在「Thinking, Fast and Slow」這本書中的理論，其對許多常見的現象如人類的直覺、錯覺、偏見等給出了解釋，並介紹了「系統1，系統2」，描述了大腦的兩種思維模式。現今的深度學習 (System 1) 直覺、快速、一目了然且非語意的。就好比我們開車在一條熟悉的道路上，並且有很多次的駕駛經驗所以會變得比較不專心。因此在開車的時候可以隨意地與乘客聊天，這些是潛意識很快又很直觀的形成。然而我們希望未來的深度學習是能夠緩慢、邏輯推理、有順序且有意識地認知。就比如開車不能玩手機一樣，因為玩手機會影響我們注意力。因此在未來的深度學習 (System 2) 講求全神關注，並在新的任務上會有一套自己的推理與認知。這也是我們希望下一代深度學習能夠擁有的審慎判斷事物的能力。

![](https://i.imgur.com/0jhWhJ9.png)

- System 1: 涉及到直覺知識，它能夠很快執行，在你大腦中是不知不覺一步一步發生，並且難以去解釋。
- System 2: 需要以一種有意識的方式，並且是可以解釋的顯性知識，涉及到了推理和規劃的方法。

> 追求AI系統需要同時完成這兩類任務

目前的深度學習是存在著隱性的知識。而我們人類卻同時具備著隱性知識與顯性知識。能夠語言化是一種特殊的知識，這也是機器難以做到的地步。因此現在的議題是如何讓機器同時有系統1與系統2的思維，並將有意識先驗放在模型的訓練框架中。其中在系統2的架構當中我們希望能夠設計出高級表徵的學習機器，利用很少的特徵進行預測，同時準確度還很高。

![](https://i.imgur.com/ocN0LUD.png)

另一個要提的是系統泛化的能力。所謂的泛化意思是我們的設計的模型可以應對未來的數據，也就是可以被廣泛使用預測並得到不錯的結果，也就是他的適應性很好。研究學者發現人類可以動態的重新組合現有的概念來形成一個新的概念，比如圖中不同類型的車輛組合成一個新的交通工具。這種概念的重組就等於我們日常生活中遇到了前所未見的事物，但是這種現象在現今的機器學習模型中是無法動態的處理而導致在新事物上泛化能力不足。正是因為模型的過度擬合，所以當分布發生重大的變化時就會表現得不好。

![](https://i.imgur.com/KuLHo2w.png)

如果想要讓 AI 變得跟人類思維一樣，就必須避免落入傳統的符號人工智慧。經典AI試圖用符號的方法完成系統2任務，但是許多的知識都包含在無意識的系統1當中。符號AI是人類可讀的表徵方法，在符號人工智慧中，有一種常用的形式是專家系統，透過 If-Then 語句的關係來處理規則，藉此進行推論。但它還有好的地方，我們可以試者將這些優點保留，例如：高效率大規模學習、系統1中根源知識的表達以及機器學習正確處理不確定性的能力。並將系統1的優點結合系統2，將知識分解之後，我們可以操縱變量、實例以及引用。

![](https://i.imgur.com/VqlA3Iq.png)

## Attention 是處理有意識的核心方法
在過去的幾年中 Ateention 機制在深度學習方面取得了不錯的進展。同時注意力將是過渡到新的深度學習的一個重要關鍵，他可以隨著時間從一個向量中取得部份重要的資訊。其中 Soft Attention 在自然語言領域已取得重大的突破，特別是在機器翻譯的部分，注意力機制能夠允許我們關注更有利的部分。有趣的是一些神經科學表示，這種注意力在就像是人類大腦內部的一種肌肉運動。

![](https://i.imgur.com/VfcDx3x.png)

全局工作空間理論 (Global workspace theory) 是美國心理學家伯納德·巴爾斯提出的意識模型。通常重要的訊息是從一個輸入當中部分被擷取出來的，並將挑選出來的訊息廣播到大腦層，儲存在短期記憶中以適應短期內的感知和行動。

![](https://i.imgur.com/9FdXRwl.png)

從人們的口述中即能判斷某些事件是有意識的還是無意識的。另外不光只是文字上解釋。能夠理解與吸收也是很重要的。因為它能將高階的特徵與較低階的感知聯繫在一起。有根源自然語言學習（Grounded language learning）是 NLP 的一個子領域，研究者試圖用除了文本之外的其他形式，例如圖像、視頻，去將語言與感知層面的知識聯繫起來，構建一個世界模型。

![](https://i.imgur.com/9jP0yDB.png)




Bengio 提出的「意識」概念的核心是注意力。他將機器注意力機制與我們的大腦選擇分配注意力的方式進行了比較：「機器學習可以用來幫助腦科學家更好地理解意識，但我們對意識的理解也可以幫助機器學習發展出更好的能力」。

## Reference
- [ICLR 2020 Yoshua Bengio：注意力是「有意識」AI的核心要素](https://kknews.cc/zh-tw/tech/x45rono.html)
- [Bengio最新演講：Representations中的深度監督學習](https://cloud.tencent.com/developer/article/1070691?from=article.detail.1370482)
- [Yoshua Bengio首次中國演講：深度學習通往人類水平AI的挑戰](https://cloud.tencent.com/developer/article/1370482)