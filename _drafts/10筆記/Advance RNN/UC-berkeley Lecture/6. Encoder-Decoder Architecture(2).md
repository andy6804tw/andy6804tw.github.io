## 前言
機器翻譯是 Seq2sqe 模型中最典型的例子，所謂的 Seq2sqe 即代表輸入與輸出都是一串序列。為了處理這個輸入與輸出都是序列的問題，我們可以設計一個包含兩個主要組件的架構。首先是 Encoder，它能夠將一長串的輸入序列編碼成一個固定形狀的狀態。第二個部分為 Decoder，他可以將先前編碼的狀態進行解碼轉換成另一個輸出序列。如下圖，以上 Seq2sqe 典型的模型我們稱為 encoder-decoder 架構。

![](https://i.imgur.com/eqcBDpA.png)

我們以中英機器翻譯為例。假設我們輸入一串英文句子: "how"、 "are"、 "you"， Encoder 會將每個輸入的單字先轉換成一個向量表示，其每個單字向量的總長度通常為英文字典單字數量。每個單字轉換成一個 one-hot 向量後經過 Encoder 的轉換後 RNN 讀了所有輸入的單字後會產生一個狀態(state)。接著 Decoder 對狀態進行解碼已生成翻譯後的序列作為輸出: "你"、 "好"、 "嗎"。因為 encoder-decoder 架構奠定了後續的 Seq2sqt 模型架構的基礎，本章節將把此架構轉換成虛擬碼，提供後續內容做更深度的實作解釋。

![](https://i.imgur.com/pgJN1mL.png)

## Encoder
Encoder 的架構與一個神經網路類似。在 Encoder 的 Class 介面中，前饋函式中的 X 表示輸入的一串序列。

```py
import tensorflow as tf

class Encoder(tf.keras.layers.Layer):
    """The base encoder interface for the encoder-decoder architecture."""
    def __init__(self, **kwargs):
        super(Encoder, self).__init__(**kwargs)

    def call(self, X, *args, **kwargs):
        raise NotImplementedError
```

## Decoder
與 Encoder 不同的是 Decoder 多了一個 `init_state()` 函式。這一個 init state 拿取 Endoer 的輸出，在 RNN 中通常是 Encoder 最後的 hidden state 作為 Encoder 的起始 state。前饋函式中有兩個輸入，分別為 X  輸入以及一個從 Encoder 傳過來的 state。接著 Decoder 將會輸出並且會修改 state。

```py
class Decoder(tf.keras.layers.Layer):
    """The base decoder interface for the encoder-decoder architecture."""
    def __init__(self, **kwargs):
        super(Decoder, self).__init__(**kwargs)

    def init_state(self, enc_outputs, *args):
        raise NotImplementedError

    def call(self, X, state, **kwargs):
        raise NotImplementedError
```

## Putting the Encoder and Decoder Together
一但建立好 Encoder 和 Decoder 後，我們可以將這兩個結構合併成一個模型。在前饋函式中，Encoder 的輸出作為 Decoder 的初始狀態，此狀態將會成為 Decoder 的其中一個輸入。Decoder 另外一個輸入為上一個自己的輸出，在訓練階段是放 Ground True。

```py
class EncoderDecoder(tf.keras.Model):
    """The base class for the encoder-decoder architecture."""
    def __init__(self, encoder, decoder, **kwargs):
        super(EncoderDecoder, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def call(self, enc_X, dec_X, *args, **kwargs):
        enc_outputs = self.encoder(enc_X, *args, **kwargs)
        dec_state = self.decoder.init_state(enc_outputs, *args)
        return self.decoder(dec_X, dec_state, **kwargs)
```

encoder-decoder 架構中的 status 狀態一詞可能啟發了你使用具有狀態的神經網絡來實現此架構。在下一節中，我們將看到如何使用 RNN 來設計基於這種 encoder-decoder 架構的序列轉導模型。

## 小結
- encoder-decoder 架構可以處理一串輸入序列和輸出另一個不同長度的序列，因此非常適合處理機器翻譯的序列問題。
- Encoder 將一組序列轉換成一個特定維度的向量輸出作為狀態(state)
- Decoder 將透過狀態資訊轉換成一個目標輸出的序列

## Reference
- [原文](https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html)