

CNN 的強大之處在於它的多層結構能自動學習特徵，並且可以學習到多個層次的特徵：較淺的卷積層感知域較小，學習到一些區域性區域的特徵。較深的卷積層具有較大的感知域，能夠學習到更加抽象一些的特徵。這些抽象特徵對物體的大小、位置和方向等敏感性更低，從而有助於識別效能的提高。

## 名詞
- 卷積核(Kernel)又稱為Filters
    - 我們可以藉由選擇Kernel的張數控制 Feature maps

## 影像的上取樣
影像的上取樣正好和卷積的方式相反，我們可以通過正常的卷積讓影像越來越小，而上取樣則可以同樣通過卷積將影像變得越來越大，最後縮放成和原影像同樣大小的圖片。上取樣有3種常見的方法：雙線性插值(bilinear)，反摺積(Transposed Convolution)，反池化(Unpooling)。

我們先來回顧一下正向卷積，也稱為下采樣，正向的卷積如下所示，首先我們擁有一個這樣的 3*3 的卷積核：

![](https://i.imgur.com/sppZpw2.png)

然後對一個`5*5`的特徵圖利用滑動視窗法進行卷積操作，padding=0,stride=1,kernel size=3,所以最後得到一個`3*3`的特徵圖：

![](https://i.imgur.com/CXNiU0A.png)

那麼上取樣呢？則是這樣的，我們假定輸入只是一個`2*2`的特徵圖，輸出則是一個`4*4`的特徵圖，我們首先將原始`2*2`的map進行周圍填充pading=2的操作，筆者查閱了很多資料才知道，這裡周圍都填充了數字0，周圍的padding並不是通過神經網路訓練得出來的數字。然後用一個kernel size=3，stride=1的感受野掃描這個區域，這樣就可以得到一個`4*4`的特徵圖了！：

![](https://i.imgur.com/72Va4Sz.png)

我們甚至可以把這個`2*2`的 feature map，每一個畫素點隔開一個空格，空格里的數字填充為0，周圍的padding填充的數字也全都為零，然後再繼續上取樣，得到一個`5*5`的特徵圖，如下所示：

![](https://i.imgur.com/DFDBNyq.png)

## 1*1 卷積
吳恩達教授在講解卷積神經網路的時候，用到了一張十分經典的影像來表示1*1卷積：

![](https://i.imgur.com/zkmaieZ.png)

原本的特徵圖長寬為28，channel為192，我們可以通過這種卷積，使用32個卷積核將28*28*192變成一個28*28*32的特徵圖。在使用1*1卷積時，得到的輸出長款保持不變，channel數量和卷積核的數量相同。可以用抽象的3d立體圖來表示這個過程：

![](https://i.imgur.com/PAGjrVu.png)

因此我們可以通過控制卷積核的數量，將資料進行降維或者升維。增加或者減少channel，但是feature map的長和寬是不會改變的。


## 結論
- 1*1 卷積是拿來控制 channel 維度
- 上取樣是用來擴增 feature map
