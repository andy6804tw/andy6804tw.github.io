
人類可以自然且有效地在復雜的場景中察覺到突出的區域。受到這一點的啟發，注意機制被引入到電腦視覺中，其目的是模仿人類視覺系統。這種注意機制可以看作是一個基於輸入圖像特徵的動態權重調整過程。注意機制在圖像分類、目標檢測、語義分割、影片理解、圖像生成、3D 視覺、多模態任務和自監督學習等視覺任務中取得了巨大的成功。本篇文章參考這篇論文： [Attention Mechanisms in Computer Vision: A Survey](https://arxiv.org/abs/2111.07624.pdf) 總結了電腦視覺中的各種注意機制，並對所有 CV Attention 研究進行分類，例如：通道注意力、空間注意力、時間注意力和分支注意力。相關的論文研究整理也能參考 GitHub 上的 repo： [Awesome-Vision-Attentions
](https://github.com/MenghaoGuo/Awesome-Vision-Attentions) 原作者統整了目前電腦視覺領域中各種注意力機制的研究。

論文首先將基於注意力的模型在計算機視覺領域中的發展歷程大致歸為了四個階段：

1. 將循環神經網路與注意力機制相結合。代表方法為 [RAM](https://www.cnblogs.com/wangxiaocvpr/p/5537454.html)。
2. 透過注意力機制將原始圖片中的空間訊息變換到另一個空間中並保留了關鍵信息。代表性方法為 STN。
3. 使用通道注意力網路自適應地採樣重要特徵。代表方法為 SENet。
4. 自注意力機制

![](https://i.imgur.com/nj2bZgD.png)


## 為什麼需要視覺注意力？
電腦視覺中的注意力機制的基本概念就是讓機器學會注意力，並能夠忽略無關的訊息從而關注重點訊息。至於為什麼要忽略無關的訊息呢？

## 模型結構簡介 (注意力分類)
就注意力關注的域來分，大致可以分成以下五種：

- 通道注意力（Channel Attention）
- 空間注意力（Spatial Attention）
- 時間注意力（Temporal Attention）
- 分支注意力（Branch Attention）
- 通道空間注意力（Channel & Spatial Attention）
- 時空注意力（Spatial & Temporal Attention）

![](https://i.imgur.com/TeJD9QY.png)

（1） 空間域

設計思路：

Spatial Transformer Networks（STN）模型是15年NIPS上的文章，這篇文章通過注意力機制，將原始圖片中的空間信息變換到另一個空間中並保留了關鍵信息。這篇文章的思想非常巧妙，因為卷積神經網絡中的池化層（pooling layer）直接用一些max pooling 或者average pooling 的方法，將圖片信息壓縮，減少運算量提升準確率。但是這篇文章認為之前pooling的方法太過於暴力，直接將信息合併會導致關鍵信息無法識別出來，所以提出了一個叫空間轉換器（spatial transformer）的模塊，將圖片中的的空間域信息做對應的空間變換，從而能將關鍵的信息提取出來。

（2） 通道域

設計思路：

通道域的注意力機制原理很簡單，我們可以從基本的信號變換的角度去理解。信號系統分析裡面，任何一個信號其實都可以寫成正弦波的線性組合，經過時頻變換之後，時域上連續的正弦波信號就可以用一個頻率信號數值代替了。

在卷積神經網絡中，每一張圖片初始會由（R，G，B）三通道表示出來，之後經過不同的捲積核之後，每一個通道又會生成新的信號，比如圖片特徵的每個通道使用64核卷積，就會產生64個新通道的矩陣（H,W,64），H,W分別表示圖片特徵的高度和寬度。每個通道的特徵其實就表示該圖片在不同卷積核上的分量，類似於時頻變換，而這裡面用卷積核的捲積類似於信號做了傅里葉變換，從而能夠將這個特徵一個通道的信息給分解成64個卷積核上的信號分量。既然每個信號都可以被分解成核函數上的分量，產生的新的64個通道對於關鍵信息的貢獻肯定有多有少，如果我們給每個通道上的信號都增加一個權重，來代表該通道與關鍵信息的相關度的話，這個權重越大，則表示相關度越高，也就是我們越需要去注意的通道了。

可參考SENet模型結構。

（3） 混合域

了解前兩種注意力域的設計思路後，簡單對比一下。首先，空間域的注意力是忽略了通道域中的信息，將每個通道中的圖片特徵同等處理，這種做法會將空間域變換方法局限在原始圖片特徵提取階段，應用在神經網絡層其他層的可解釋性不強。

而通道域的注意力是對一個通道內的信息直接全局平均池化，而忽略每一個通道內的局部信息，這種做法其實也是比較暴力的行為。所以結合兩種思路，就可以設計出混合域的注意力機制模型

## Transformer 為何比 CNN 好？
Transformer 在 NLP 中取得成功，其中 attention 是重要的關鍵元素。更重要的是它丟棄了原先 RNN seq2seq 的架構，並採用 self-attention 在 seq2seq 架構上學習。從最終的訓練結果來看 Transformer 對於大數據的適應能力非常強。這一點非常重要，因為當電腦視覺特別是 CNN 發展到一定階段會遇到一些瓶頸。這些瓶頸來至於訓練的 data scale，因為現在很多 CNN 的模型都是採用於監督式學習。當 CNN 模型採用大量的資料學習以後，我們會發現模型會對資料的適應能力沒有想像中的好。此時 Transformer 的橫空出世將 NLP 任務上得到的經驗套用在電腦視覺領域上面並有不錯的效果。我們能明顯看到隨著數據的增加他的效能可以繼續的成長。至於為何 Transformer 這麼強大呢？其中關鍵因素是它的每個注意力分數是可以動態的，而 CNN 很多學習的參數一但學完以後他就是 fixed 住不動了。

因此這個動態的注意力參數就很厲害了，因為這個模型隨著每次看這個圖會計算一個注意力分數。並透過這組分數幫助模型更關注重點。這也是為什麼最近在 CNN 研究中有個叫 Dynamic Network，其就是引入了這個思想運用在卷積層或是激發層例如：dynamic convolution、dynamic relu。

Attention 其實更關注特徵彼此之間的相互關係。在早期的圖像匹配中最經典的方法是 SIFT 利用特徵點描述及比對來間接兩張圖的關聯性。SIFT 的 interest point 實際上可以學到圖中的哪些點是更突出具有代表性的。CNN 這種模型其實圖過級聯的關係可以學到不同尺度上的資訊，就好比影像中的 interest point。至於 Transformer 考慮了這個特徵學完以後跟另一個特徵他們之間有什麼相對關係。所以從這個角度來看這個模型的適應能力會更好，因為它不完全依賴於數據本身。因此輸入的影像畫素值變的不是非常重要，反而它更關注了物體之間的相互關聯性。然後還有一個事情就是 Transformer 的注意力機制可以不僅僅關注 local 的訊息，它從 local 到 global 這樣一個擴散的機制去尋找表徵。除此之外其實 Transformer 是非常暴力的，它從低階的特徵開始就可以看全局的資訊，並建立與全局關鍵點之間的關聯性。當隨著層數加深這些 local 的點就會聚成了一些 corner point，接著再透過這些內容去找彼此間的關聯性。

![](https://i.imgur.com/K55ywle.png)

話又說回來 CNN 也是有他的可用之處，例如平移、縮放不變性。那將這件事情放到 Transformer 機制上其實是不具備的。因此最簡單的 Transformer 應用到視覺上例如像是目標檢測會出現問題的。因此有相研究將卷積與 Transformer 結合，有一系列的研究例如： Swin、CvT、CSwin、Focal Transformer 等。

[參考](https://www.bilibili.com/video/BV1L3411x7hw/?spm_id_from=trigger_reload)