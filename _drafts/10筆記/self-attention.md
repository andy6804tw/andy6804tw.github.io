
self-attention 要解決什麼問題呢？到目前為止我們所遇到的神經網路的輸入都是一個向量，不管是數值型預測、影像...等。然而輸出可能是一個連續數值(Regression)或是類別(Classfication)。假設我們遇到更複雜的問題，他的輸入是一排向量，而且輸入的向量數目是會改變的呢(sequence的長度數目不一樣)？

![](https://i.imgur.com/eiJmkK0.png)

這裡舉一個輸入是一個 Sequence 而且長度會改變的例子，文字處理。假設我們的網路的輸入是一個句子，每一個句子詞彙數目不同。如果我們把每個詞彙都描述成一個向量表示，那我們的veter set大小就會不一樣。那怎麼把一個詞彙表示成一個向量呢？最簡單的方式是 One-Hot 的 Encoding，這向量的長度也就是世界上所有的詞彙。但是這樣的表示方式會有一個非常嚴重的問題，假設所有的詞彙彼此之間都是沒有關係的。從這個向量中我們無法得到任何語意資訊。有另一種方法叫做 Word Embedding，所謂的 Word Embedding 就是我們會給每一個詞彙一個向量。而這個向量是有語意資訊的，如果你將 Word Embedding 後的結果畫出來，你會發現所有相同類別的會聚集成一團。 

![](https://i.imgur.com/I9TKig1.png)

另一個例子是音訊處理，一段聲音訊號其實就是一排向量。我們會把一段聲音訊號擷取一個範圍，這個範圍我們稱之為 window。我們將每一個 window 資訊描述成一個向量，這個向量稱之為 Frame。我們會有各式各樣的方法，可以用一個向量來描述，一小段 25 個 Millisecond 裡面的語音訊號。

![](https://i.imgur.com/LBBne3k.png)

還有什麼東西是一堆向量呢？一個圖(Graph)也是一堆向量，在 Social Network上面每一個節點就是一個人，節點與節點之間代表就有關係。而每一個節點就可以看作是一個向量，包含每個人的性別、年齡、工作...等，把這些資訊用一個向量來表示。所以一個 Social Network 也可以看作是一堆的向量所組成。

![](https://i.imgur.com/C82SFe5.png)

還有什麼是與 Graph 有關的呢？舉例來說一分子，他也能看作是一個 Graph。每個分子上面的球也就是原子，就是一個向量。

![](https://i.imgur.com/GgbGwJb.png)

我們剛才已經看了輸入是一堆向量的例子了，他可以是文字、語音或圖。那這個時候我們可能會有什麼輸出呢？這裡有三種可能性，第一種每一個向量都有一個對應的標籤。也就是說當你的模型到四個輸入向量的時候，他就要輸出四個標籤。最常見的例子就是 POS Tagging 詞性標注，要讓機器自動決定每一個詞彙他是什麼樣的詞性。

![](https://i.imgur.com/LDe7mjQ.png)

第二種可能的輸出是我們一整個 Senquence 只需要輸出一個標籤就好。舉例來說如果是文字的語意分析，透過給定一串文字，來判定這一句話是正面還是負面。或是聽一段聲音判斷是誰講的話。