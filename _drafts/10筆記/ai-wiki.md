# AI 小百科

## 歸納偏置（inductive biases）
是從一些例子中尋找共性、泛化，形成一個比較通用的規則的過程，使得模型產生偏好。和貝葉斯學習中的先驗(Prior)有異曲同工之妙。從現實生活中觀察到的現像中歸納出一定的規則，選擇出更符合現實規則的模型。在卷積神經網絡中，我們假設特徵具有局部性(Locality)的特性，即當我們把相鄰的一些特徵放在一起，會更容易得到解。

## 消融實驗 (ablation study)
一些新穎的深度學習模型在論文中都會進行 Ablation Study，這部分的主要意義在於系統性的移除模型中的各種組件/trick等因子或者是創新的方法，來探究各個因素對於模型整體貢獻的強弱多寡，找到對性能最主要的影響因素。

## 統計學習 (Statistical learning)
統計學習可以說是機器學習的數理基礎，是以統計學及數學的觀點闡述(推導)機器學習演算法的理論、參數性質及模型評估。

## 預測 (prediction)
所謂的預測主要是希望能夠估計一個函數 `f()` 使得輸入自變數 (x) 得到一個預測輸出 (y^)。目標是模型預測的 y^ 要與真實的答案 y 越接近越好，也就是誤差越小越好。

## 推論 (inference)
推論的目的也是要估計一個好的函數 `f()`。不過推論所關注的內容在於觀察輸入特徵 (x) 與輸出 (y) 之間的關聯性。例如觀察房間坪數是否與房價呈現線性關聯。

# 影像視覺
## 平移不變性（translation equivariance）
在影像分類任務中，平移不變性就是影像中的目標不管被移動到哪個位置，模型給出的標籤應該都是相同的。

## Feature Pyramid Network
那就是跳連線相加可以實現不同解析度特徵的組合，因為淺層容易有高解析度但是低階語義的特徵，而深層的特徵有高階語義，但解析度就很低了。(DenseNet)