## AI 小百科

## 歸納偏置（inductive biases）
是從一些例子中尋找共性、泛化，形成一個比較通用的規則的過程，使得模型產生偏好。和貝葉斯學習中的先驗(Prior)有異曲同工之妙。從現實生活中觀察到的現像中歸納出一定的規則，選擇出更符合現實規則的模型。在卷積神經網絡中，我們假設特徵具有局部性(Locality)的特性，即當我們把相鄰的一些特徵放在一起，會更容易得到解。

## 消融實驗(ablation study)
一些新穎的深度學習模型在論文中都會進行 Ablation Study，這部分的主要意義在於系統性的移除模型中的各種組件/trick等因子或者是創新的方法，來探究各個因素對於模型整體貢獻的強弱多寡，找到對性能最主要的影響因素。

# 影像視覺
## 平移不變性（translation equivariance）
在影像分類任務中，平移不變性就是影像中的目標不管被移動到哪個位置，模型給出的標籤應該都是相同的。