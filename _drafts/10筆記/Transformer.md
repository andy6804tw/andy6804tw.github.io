# 影片課程
[NTU ML Course](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html)
[STAT 157, UC Berkeley, Spring, 2019](https://courses.d2l.ai/berkeley-stat-157/index.html)

## 線上資源
[Dive into Deep Learning](https://d2l.ai/chapter_attention-mechanisms/index.html)
[ai-scholar](https://ai-scholar.tech/en/category/transformer)

# 相關文章 
[Attention Mechanism詳細介紹：原理、分類及應用](https://zhuanlan.zhihu.com/p/31547842)
[用Transformer完全替代CNN](https://a1053305.medium.com/vit-vision-transformer-convolution-is-dead-long-live-the-self-attention-bbced72a8487)
[ BERT 科普文](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html)
[目前主流的attention方法](https://www.zhihu.com/question/68482809)
[Attention注意力機制+Transformer詳解](http://www.uml.org.cn/ai/202009301.asp)
[Attention注意力機制+Transformer詳解](https://zhuanlan.zhihu.com/p/53682800)
[再談注意力機制| 運用強化學習實現目標特徵提取](https://zhuanlan.zhihu.com/p/141893885)
[基於注意力機制的多智能體強化學習的演員評論家算法](https://zhuanlan.zhihu.com/p/70947214)
[深度強化學習中狀態注意力機制的研究](http://html.rhhz.net/tis/html/201809033.htm)
[深度學習中的注意力機制 (一)](https://www.mdeditor.tw/pl/poqR/zh-tw)
[深度學習中的注意力機制 (二)](https://www.mdeditor.tw/pl/pjyD/zh-tw)
[深度學習中的注意力機制 (三)](https://www.mdeditor.tw/pl/ggUm/zh-tw)

## 輪文
[AAAI21 Informer:最強最快的序列預測神器](https://mp.weixin.qq.com/s/RRv-DVm6SguQ5GC5oruf8Q)


 