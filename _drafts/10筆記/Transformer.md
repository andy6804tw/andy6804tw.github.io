# 影片課程
[NTU ML Course](http://speech.ee.ntu.edu.tw/~tlkagk/courses_ML20.html)
[STAT 157, UC Berkeley, Spring, 2019](https://courses.d2l.ai/berkeley-stat-157/index.html)

## 線上資源
[Dive into Deep Learning](https://d2l.ai/chapter_attention-mechanisms/index.html)
[ai-scholar](https://ai-scholar.tech/en/category/transformer)

# 相關文章 
[Attention Mechanism詳細介紹：原理、分類及應用](https://zhuanlan.zhihu.com/p/31547842)
[用Transformer完全替代CNN](https://a1053305.medium.com/vit-vision-transformer-convolution-is-dead-long-live-the-self-attention-bbced72a8487)
[ BERT 科普文](https://leemeng.tw/attack_on_bert_transfer_learning_in_nlp.html)


## 輪文
[AAAI21 Informer:最強最快的序列預測神器](https://mp.weixin.qq.com/s/RRv-DVm6SguQ5GC5oruf8Q)
