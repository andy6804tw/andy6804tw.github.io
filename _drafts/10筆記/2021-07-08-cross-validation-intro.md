---
layout: post
title: '[機器學習] 交叉驗證 Cross-Validation 簡介'
categories: 'AI'
description:
keywords: Cross-Validation
---

## 前言
在解釋交叉驗證之前我們先來討論一下將資料集切分為訓練集、測試集和驗證集的問題。在一般狀況下我們會將資料先切割成兩等份，分別為訓練集和測試集。其中在模型訓練時，模型只會對訓練集進行擬和。另外測試集的資料並未參與訓練，因此可以拿來當作最終評估模型的好壞。我們的目標是要讓模型在訓練集和測試集都有不錯的成績，也就是說 loss 要越低越好。為了避免模型訓練發生過度擬和，通常我們還會從訓練集切一小部分資料出來進行驗證。驗證集的用處則是用來檢視模型在訓練過程中每次的迭代結果訓練的好不好。但該如何切出這個驗證集比較有公信力呢？如果我們僅切一小份的資料他是能有有效的評估訓練時模型的好壞嗎？在某些情況底下單純直接從資料集裡面切一塊出來當驗證集，是沒有辦法很有效的去評估一個模型訓練的好壞。說不定訓練出來的模型在這一份驗證集恰好表現得不錯，如果又隨機抽另一份資料來當驗證集說不定結果會變得很糟糕。這就表示模型泛化能力不足。為了避免這種情況發生並且有效的切割驗證集來評估模型，我們可以採用交叉驗證 Cross-Validation 的技巧來獲得最佳驗證。


