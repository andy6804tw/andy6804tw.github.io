## 前言
這一章節我們要來談談如何將上一篇文所提到的 Attention 機制實際套用在 Seq2seq 模型。

## Seq2sqe model with Attention
在每一個 Decoder 時間點，



## Reference
- [簡報](https://courses.d2l.ai/berkeley-stat-157/slides/4_25/24-Attention.pdf)
- [影片](https://www.youtube.com/watch?v=NBVjgRJZLcU)